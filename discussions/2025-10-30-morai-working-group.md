## 30 Oct 2025 | MORAI working group kick-off meeting

### Attendees:

- [Florent Zara](mailto:florent.zara@eclipse-foundation.org)
- [Johann Diedrick](mailto:johann@mozillafoundation.org)
- [Nina Zhou](mailto:nnzhou@thoughtworks.com)
- [Jesse McCrosky](mailto:jesse.mccrosky@egen.ai)
- [Xiaohu Zhu](mailto:xhzhu.nju@gmail.com)
- [Christian Maitre](mailto:cmaitre@caspera-lab.com)
- [Chris Xie](mailto:cxie2@futurewei.com)  
---

### 1\. Main Topics Discussed

* Attendee introductions, including their backgrounds and organizational affiliations.  
* Group operating procedures, specifically regarding the public sharing of meeting notes.  
* Defining the working group's name, mission, and key differentiators.  
* Brainstorming ideas for concrete projects the group can undertake.  
* Review of existing group assets (GitHub repository and website).  
* Assignment of action items and scheduling the next meeting.

---

### 2\. Essential Discussions and Decisions

* **Introductions:** Members introduced themselves, representing organizations such as GOSIM Foundation, the Eclipse Foundation, the Mozilla Foundation (Mozilla Data Collective), the Center for Safe AGI, and Caspera Lab. Backgrounds cover open-source strategy, AI safety, open data, and AI maturity models.  
* **Group Name:** The group officially adopted the name **MORAI (Multicultural Open Responsible AI)**, which was proposed by Xiaohu Zhu. This name resonates with “Moral”.  
* **Operating Procedure:** The group confirmed its intention to work "very much in the open"15. A decision was made to publish **curated meeting notes/minutes** to the GitHub repository rather than raw, unverified AI transcripts to ensure accuracy.  
* **Group Mission & Differentiator:** The group will provide **thought leadership** and drive the development of **practical solutions and tools** that make its vision a reality. The strategy is for this core team to create the initial designs and strategy, then engage the broader open-source community to help build and scale the projects.  
* **Project Brainstorming:** Three main project ideas were proposed:  
  1. **"True" Framework Dashboard:** Expand on an existing demo (Transparent, Understandable, Reproducible, Executable) to create an **automated dashboard** that evaluates and tracks the openness of various large language models over time.  
  2. **AI Safety "Arena":** Build a platform similar to "[LLM Arena](https://lmarena.ai/)" but focused on AI safety, specifically to **measure and track LLM persuasiveness** at scale.  
  3. **Ecosystem Landscape Map:** Create a "landscape view" document that **maps the major organizations, projects, and players** in the responsible AI and governance space. This would help identify gaps, avoid redundant work, and find collaboration opportunities.

### 3\. Key Takeaways

* The group's identity is centered on combining a **multicultural, global perspective** with **open-source principles**.  
* The primary strategic focus will be on **producing tangible tools and prototypes**, which members from Mozilla and GOSIM are well-positioned to support.  
* The group views modern AI as an enabler, making it much faster and easier to turn ideas into functional demos.

### 4\. Tasks Assigned

* **Draft curated meeting minutes** from the transcript and share via Google Doc for group review. — **Florent Zara** — By Oct 31, 2025\.  
* **Create the initial "landscape view" document** (listing responsible AI organizations) in the GitHub repository. — **Chris Xie** — No deadline specified.  
* **Send a Doodle poll** to schedule the next meeting, targeting the last two weeks of November. — **Jesse McCrosky** — By Oct 31, 2025\.

### 5\. Follow-Up Actions

* Review the [group's GitHub repository](https://github.com/aivisionforum/ai-ethics-governance) and the [visionforum.ai website](http://visionforum.ai). — **All Attendees**  
* Collaborate on drafting a short **mission statement or manifesto** (approx. half a page) to clarify the group's purpose. Reference the current [readme.md](https://github.com/aivisionforum/ai-ethics-governance/blob/main/README.md) in the Github repo. — **All Attendees**  
* Write up and contribute **brief proposals for concrete projects** the group could undertake. — **All Attendees**  
* Share information about the upcoming AI safety workshops in Shanghai for remote participation. — **Xiaohu Zhu**

### 6\. Open Issues / Topics for Future Discussion

* Prioritizing which concrete projects (e.g., "true" dashboard, safety arena, landscape map) the group will focus on first.  
* Developing a strategy to recruit new members from under-represented global regions.  
* Defining a more formal agenda and long-term plan for the group.

